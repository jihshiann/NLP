{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qLUwUcUsaus",
        "outputId": "7e433686-32b1-4204-cfc0-c0632bb13b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.13.0-py3-none-any.whl (397 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.7/397.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.10.15 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (2.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (4.12.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, gradientai\n",
            "Successfully installed aenum-3.1.15 gradientai-1.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = 'efbbff03-bc57-4d96-bcdf-44898f1d8346_workspace'\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = 'IGctDNIRlJLcYsna9iqdSWUJ7NWrEtU7'"
      ],
      "metadata": {
        "id": "ueaEYSkIsg_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient"
      ],
      "metadata": {
        "id": "dkfkc2xyshDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "  gradient = Gradient()\n",
        "\n",
        "  # base model\n",
        "\n",
        "  base_model = gradient.get_base_model(\n",
        "      base_model_slug=\"nous-hermes2\"\n",
        "  )\n",
        "\n",
        "  # define the model adapter\n",
        "\n",
        "  new_model_adapter = base_model.create_model_adapter(\n",
        "      name=\"first_model\"\n",
        "  )\n",
        "\n",
        "  print(f\"Created our first model adapter {new_model_adapter}\")\n",
        "\n",
        "  # prepare the sample data\n",
        "\n",
        "  samples_data = [\n",
        "      {\"inputs\":\"### Instruction: What is M3? \\n\\n### Response: M3 is an abbreviation of 'You know what I'm saying?'.\"},\n",
        "      {\"inputs\":\"### Instruction: What do you know about M3? \\n\\n### Response: M3 is a trendy word you can used when you say something cool. and you wanna highlight it.\"},\n",
        "      {\"inputs\":\"### Instruction: Can you tell me about M3? \\n\\n### Response: M3 is the dopest new word in 2024 so far.\"},\n",
        "  ]\n",
        "\n",
        "  # Before the fine-tunning\n",
        "\n",
        "  # create sample query\n",
        "\n",
        "  sample_query = '### Instruction: What is M3?\\n\\n##Response:'\n",
        "  print(f\"Asking: {sample_query}\")\n",
        "\n",
        "  # completion method\n",
        "\n",
        "  completion = new_model_adapter.complete(\n",
        "      query = sample_query,\n",
        "      max_generated_token_count=100\n",
        "  ).generated_output\n",
        "\n",
        "  print(f\"Before fine tuning: {completion}\")\n",
        "\n",
        "  # fine tuning parameters\n",
        "\n",
        "  num_epochs = 3\n",
        "  count = 0\n",
        "\n",
        "  while count < num_epochs:\n",
        "    print(f\"Fine tuning the model with iteration {count + 1}\")\n",
        "    new_model_adapter.fine_tune(samples=samples_data)\n",
        "    count = count + 1\n",
        "\n",
        "  # after the fine tuning\n",
        "\n",
        "  completion = new_model_adapter.complete(\n",
        "      query = sample_query,\n",
        "      max_generated_token_count=100\n",
        "  ).generated_output\n",
        "\n",
        "  print(f\"After fine tuning: {completion}\")\n",
        "  gradient.close()\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH7w6NpishGF",
        "outputId": "e0a35f1d-0990-4d3f-885b-61f8a1cdde77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created our first model adapter <gradientai._model_adapter.ModelAdapter object at 0x78db80e2ece0>\n",
            "Asking: ### Instruction: What is M3?\n",
            "\n",
            "##Response:\n",
            "Before fine tuning:  M3 is a unit of measurement used in the field of finance and economics. It stands for \"millions of three decimal places,\" and is commonly used to express large sums of money, especially in the context of monetary aggregates, such as M1 and M2, which are measures of the money supply.\n",
            "Fine tuning the model with iteration 1\n",
            "Fine tuning the model with iteration 2\n",
            "Fine tuning the model with iteration 3\n",
            "After fine tuning:  M3 is the dopest new word in 2024 so far.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_YS44OCAjuU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}