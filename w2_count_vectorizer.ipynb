{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPavlTUY5ObhH3N0wz4Fhoq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MNxBvia0hg1k"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import train_test_split\n","\n","import nltk\n","from nltk import word_tokenize\n","from nltk.stem import WordNetLemmatizer, PorterStemmer\n","from nltk.corpus import wordnet"]},{"cell_type":"code","source":["nltk.download(\"wordnet\")\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"],"metadata":{"id":"tyOBO27xhjSp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://www.kaggle.com/shivamkushwaha/bbc-full-text-document-classification\n","!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv"],"metadata":{"id":"Z7wIungZhzLg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('bbc_text_cls.csv')"],"metadata":{"id":"RQDxFyG2ioZa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"ad1eXgyQir_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"id":"OmHUsejMiu9i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = df['text']\n","labels = df['labels']"],"metadata":{"id":"kgPdzYQci64s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels.hist(figsize=(10, 5))"],"metadata":{"id":"PZIoLtyXi1Wd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs_train, inputs_test, Ytrain, Ytest = train_test_split(\n","    inputs, labels, random_state=123)"],"metadata":{"id":"61DTxMM0i4G6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorizer = CountVectorizer()"],"metadata":{"id":"HLu0iDI1jYDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Xtrain = vectorizer.fit_transform(inputs_train)\n","Xtest = vectorizer.transform(inputs_test)"],"metadata":{"id":"vg7CZsKpjZkU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Xtrain"],"metadata":{"id":"zZ12v5EDjbB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(Xtrain != 0).sum()"],"metadata":{"id":"gvHgJZgmjcSz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# what percentage of values are non-zero?\n","(Xtrain != 0).sum() / np.prod(Xtrain.shape)"],"metadata":{"id":"9SZRaImOjgBv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MultinomialNB()\n","model.fit(Xtrain, Ytrain)\n","print(\"train score:\", model.score(Xtrain, Ytrain))\n","print(\"test score:\", model.score(Xtest, Ytest))"],"metadata":{"id":"BHN2BxnqjjOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with stopwords\n","vectorizer = CountVectorizer(stop_words='english')\n","Xtrain = vectorizer.fit_transform(inputs_train)\n","Xtest = vectorizer.transform(inputs_test)\n","model = MultinomialNB()\n","model.fit(Xtrain, Ytrain)\n","print(\"train score:\", model.score(Xtrain, Ytrain))\n","print(\"test score:\", model.score(Xtest, Ytest))"],"metadata":{"id":"luTpQCrUjmQ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_wordnet_pos(treebank_tag):\n","  if treebank_tag.startswith('J'):\n","    return wordnet.ADJ\n","  elif treebank_tag.startswith('V'):\n","    return wordnet.VERB\n","  elif treebank_tag.startswith('N'):\n","    return wordnet.NOUN\n","  elif treebank_tag.startswith('R'):\n","    return wordnet.ADV\n","  else:\n","    return wordnet.NOUN"],"metadata":{"id":"uYzdIJn7jqcH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LemmaTokenizer:\n","  def __init__(self):\n","    self.wnl = WordNetLemmatizer()\n","  def __call__(self, doc):\n","    tokens = word_tokenize(doc)\n","    words_and_tags = nltk.pos_tag(tokens)\n","    return [self.wnl.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in words_and_tags]"],"metadata":{"id":"NVoaZv1djthE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with lemmatization\n","vectorizer = CountVectorizer(tokenizer=LemmaTokenizer())\n","Xtrain = vectorizer.fit_transform(inputs_train)\n","Xtest = vectorizer.transform(inputs_test)\n","model = MultinomialNB()\n","model.fit(Xtrain, Ytrain)\n","print(\"train score:\", model.score(Xtrain, Ytrain))\n","print(\"test score:\", model.score(Xtest, Ytest))"],"metadata":{"id":"QnkKYPnvjvTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class StemTokenizer:\n","  def __init__(self):\n","    self.porter = PorterStemmer()\n","  def __call__(self, doc):\n","    tokens = word_tokenize(doc)\n","    return [self.porter.stem(t) for t in tokens]"],"metadata":{"id":"sOI7JdG3jwut"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with stemming\n","vectorizer = CountVectorizer(tokenizer=StemTokenizer())\n","Xtrain = vectorizer.fit_transform(inputs_train)\n","Xtest = vectorizer.transform(inputs_test)\n","model = MultinomialNB()\n","model.fit(Xtrain, Ytrain)\n","print(\"train score:\", model.score(Xtrain, Ytrain))\n","print(\"test score:\", model.score(Xtest, Ytest))"],"metadata":{"id":"cVA4QdpQkBIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def simple_tokenizer(s):\n","  return s.split()"],"metadata":{"id":"Hct7wmEZkDWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# string split tokenizer\n","vectorizer = CountVectorizer(tokenizer=simple_tokenizer)\n","Xtrain = vectorizer.fit_transform(inputs_train)\n","Xtest = vectorizer.transform(inputs_test)\n","model = MultinomialNB()\n","model.fit(Xtrain, Ytrain)\n","print(\"train score:\", model.score(Xtrain, Ytrain))\n","print(\"test score:\", model.score(Xtest, Ytest))"],"metadata":{"id":"yxNBzErIkIeL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Practice"],"metadata":{"id":"96-ptgmGkRgL"}},{"cell_type":"code","source":["# What is the vector dimensionality in each case?\n","# Compare them and consider why they are larger / smaller\n"],"metadata":{"id":"LqTAPAUXkNIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-L2onTEsCV2N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SHjKu6InE4gx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WgPGofA9E4jF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rl1dF4VBE4lS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8yML20B8E4nm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ogN-Ff4KE4qA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gMWI637jE4sU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nvUsrImlE4u1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fWEUfqI6E4xq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hbvqgS-yE4z2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vbH84_QhE42M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rbKk4D1-E44d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DIAgE-azE48F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Gs7F3UJCE5Aj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# stopwords: 25995\n","# lemmatization: 26000\n","# stemming: 22828\n","# simple: 52144"],"metadata":{"id":"dtE87y7AE5ES"},"execution_count":null,"outputs":[]}]}